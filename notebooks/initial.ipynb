{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T20:15:56.061116Z",
     "start_time": "2025-03-22T20:15:51.074168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, dtype\n",
    "\n",
    "from src.engine.generate import generate\n",
    "from src.models.character_generator import CharacterGenerator\n",
    "from src.transformer.dot_product_attention import DotProductAttention\n",
    "\n",
    "\n",
    "class DynamicPositionEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, max_seq_length: int = 0, embedded_dim: int = 0,\n",
    "                 scaling_factor: int = 10000, device = None):\n",
    "        super(DynamicPositionEncoding, self).__init__()\n",
    "        self.scaling_factor: int = scaling_factor\n",
    "        self.device = device\n",
    "        self.position_encodings: torch.Tensor = self.encode((max_seq_length, embedded_dim))\n",
    "\n",
    "    def encode(self, input_dims: tuple):\n",
    "        embedded_dim: int = input_dims[-1]\n",
    "        seq_length: int = input_dims[-2]\n",
    "\n",
    "        position_encodings = torch.zeros(seq_length, embedded_dim)\n",
    "        if is_odd := embedded_dim % 2 != 0: embedded_dim += 1\n",
    "\n",
    "        raw_positions = (torch.arange(seq_length, device= self.device).unsqueeze(1) /\n",
    "                         (self.scaling_factor ** (torch.arange(0, embedded_dim, 2, device= self.device) / embedded_dim)))\n",
    "        position_encodings[:, 0::2] = torch.sin(raw_positions)\n",
    "        position_encodings[:, 1::2] = torch.cos(raw_positions[:, :-1] if is_odd else raw_positions)\n",
    "        return position_encodings\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if (x.shape[-2] > self.position_encodings.shape[-2] or\n",
    "                x.shape[-1] != self.position_encodings.shape[-1]):\n",
    "            self.position_encodings = self.encode(x.shape)\n",
    "        return x + self.position_encodings[:x.shape[-2], :]\n",
    "\n",
    "t = torch.zeros(2, 2, 6)\n",
    "posEn = DynamicPositionEncoding(3, t.shape[-1])\n",
    "\n",
    "posEn.forward(t)"
   ],
   "id": "17654ff445cac3f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/v8/_7nzg4ln01d8js37_knftkp40000gp/T/ipykernel_50599/2484075740.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "         [0.8415, 0.5403, 0.0464, 0.9989, 0.0022, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "         [0.8415, 0.5403, 0.0464, 0.9989, 0.0022, 1.0000]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T17:21:53.896197Z",
     "start_time": "2025-03-16T17:21:53.768938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "x = torch.zeros(2, 2, 5) - 1\n",
    "x[0, 0, 0] = 0\n",
    "q = torch.randn(2, 2, 5)\n",
    "k = torch.randn(2, 2, 5)\n",
    "v = torch.randn(2, 2, 5)\n",
    "embedded_dims = 5\n",
    "raw_attention = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(embedded_dims)\n",
    "\n",
    "mask_val = -1\n",
    "if mask_val is not None:\n",
    "    raw_attention.masked_fill(x == mask_val, -1e8)\n",
    "\n",
    "\n",
    "\n",
    "attention_scores = softmax(raw_attention)\n",
    "attention = torch.matmul(attention_scores, v)\n",
    "\n",
    "attention, mask, raw_attention + mask\n"
   ],
   "id": "c297a6bed8533774",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask_val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     seq_length \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m---> 15\u001B[0m     \u001B[43mraw_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmasked_fill\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmask_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1e8\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m attention_scores \u001B[38;5;241m=\u001B[39m softmax(raw_attention)\n\u001B[1;32m     20\u001B[0m attention \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(attention_scores, v)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (5) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T00:44:10.717381Z",
     "start_time": "2025-03-16T00:44:10.669116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.transformer.dot_product_attention import DotProductAttention\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "attention_heads = [DotProductAttention(16, 2) for _ in range(8)]\n",
    "x = torch.randn((2,3,16))\n",
    "\n",
    "z = [attention_head(x) for attention_head in attention_heads]\n",
    "y = torch.concatenate(\n",
    "            z, dim=-1\n",
    "        )\n",
    "#y.permute(0, 2, 1, 3).reshape(2, 3, 8 * 2)\n",
    "y.shape, z[1].shape"
   ],
   "id": "a2812b46365fb328",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 16]), torch.Size([2, 3, 2]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T15:26:46.647810Z",
     "start_time": "2025-03-16T15:26:46.574034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.randn((2,3,4))\n",
    "\n",
    "mean = torch.mean(x, dim=-1)\n",
    "sd =torch.var(x, dim= -1)\n",
    "xp = x - mean / torch.sqrt(sd + 1e-5)\n",
    "\n",
    "x, xp.shape"
   ],
   "id": "bf83a3bcc3f11dbf",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m mean \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(x, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      4\u001B[0m sd \u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mvar(x, dim\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m xp \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmean\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43msd\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1e-5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m x, xp\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T18:36:49.134842Z",
     "start_time": "2025-03-16T18:36:49.108090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.zeros((2, 3), dtype = torch.int64)\n",
    "y: torch.Tensor = torch.rand((2, 5, 8))\n",
    "\n",
    "x = [\n",
    "            [y[batch, idx, :] for idx in x[batch, :]]\n",
    "            for batch in range(x.shape[0])\n",
    "        ]\n",
    "x = torch.stack([torch.stack(sublist, dim=0) for sublist in x], dim=0)\n",
    "x.shape"
   ],
   "id": "4e59c86a448c4eeb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T01:19:56.630749Z",
     "start_time": "2025-03-17T01:19:56.606079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "mask = torch.triu(torch.ones(3, 3), diagonal=1) * -1e8\n",
    "mask = mask.unsqueeze(0).expand(2, -1, -1)\n",
    "mask"
   ],
   "id": "a0597153cbd91a53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[        -0., -100000000., -100000000.],\n",
       "         [        -0.,         -0., -100000000.],\n",
       "         [        -0.,         -0.,         -0.]],\n",
       "\n",
       "        [[        -0., -100000000., -100000000.],\n",
       "         [        -0.,         -0., -100000000.],\n",
       "         [        -0.,         -0.,         -0.]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T16:28:21.699720Z",
     "start_time": "2025-03-23T16:28:21.598889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "file_path = \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/resources/bee_movie.txt\"\n",
    "\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    macbeth = f.read()\n",
    "\n",
    "len(macbeth)\n",
    "class CharacterDataset(Dataset):\n",
    "\n",
    "    def __init__(self, input_text, block_size: int):\n",
    "        super().__init__()\n",
    "        self.text = input_text\n",
    "        self.block_size = block_size\n",
    "        self.characters = sorted(set(input_text))\n",
    "        self.encode = {char: idx for idx, char in enumerate(self.characters)}\n",
    "        self.decode = {idx: char for idx, char in enumerate(self.characters)}\n",
    "        self.encoded_text = torch.Tensor([self.encode[char] for char in input_text])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_text) - (self.block_size + 1)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        return self.encoded_text[idx:idx + self.block_size], self.encoded_text[idx + self.block_size]\n",
    "\n",
    "train_split: int = int((len(macbeth) - 1) * 0.9)\n",
    "train_dataset = CharacterDataset(macbeth[:train_split], 256)\n",
    "test_dataset = CharacterDataset(macbeth[train_split:], 256)\n",
    "full_dataset = CharacterDataset(macbeth, 256)\n",
    "train_dataloader = DataLoader(dataset= train_dataset,\n",
    "                              batch_size= 128)\n",
    "test_dataloader = DataLoader(dataset= test_dataset,\n",
    "                             batch_size= 128)\n",
    "print(set(test_dataset.characters).difference(train_dataset.characters))\n",
    "print(set(train_dataset.characters).difference(test_dataset.characters))\n",
    "len(full_dataset.characters), len(train_dataset.characters), len(test_dataset.characters)"
   ],
   "id": "258caf02c75240a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{'Q', 'U', '8', ':', '0', '9', '3', '5', '6', '1', '4'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70, 70, 59)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T16:28:17.551827Z",
     "start_time": "2025-03-23T16:28:17.491235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "invisible_chars = ['\\u2006', '\\ufeff']\n",
    "\n",
    "with open(\"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/resources/bee_movie.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "for char in invisible_chars:\n",
    "    text = text.replace(char, '')\n",
    "\n",
    "with open(\"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/resources/bee_movie.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)"
   ],
   "id": "c222ef05a2abb15e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T02:13:52.061178Z",
     "start_time": "2025-03-21T02:13:52.042307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_target = torch.zeros((2, 3))\n",
    "logits = torch.ones((2, 3, 4))\n",
    "logits[0][0][0] = 0\n",
    "\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "accuracy = (y_target == torch.argmax(softmax(logits), dim= -1)).sum().item() / (len(y_target) * y_target.shape[1])\n",
    "\n",
    "\n",
    "y_target, torch.argmax(softmax(logits), dim= -1), accuracy\n",
    "\n"
   ],
   "id": "90108e866411eeee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([[1, 0, 0],\n",
       "         [0, 0, 0]]),\n",
       " 0.8333333333333334)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T14:37:45.927960Z",
     "start_time": "2025-03-23T14:37:37.373367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.io import load_model, get_text\n",
    "from src.utils.character_dataset import CharacterDataset\n",
    "from src.models.character_generator import CharacterGenerator\n",
    "\n",
    "model = CharacterGenerator(vocab_size=75,\n",
    "                           embedding_dim=256,\n",
    "                           num_transformers=8,\n",
    "                           num_heads=8,\n",
    "                           ffnn_hidden_neurons=1024)\n",
    "\n",
    "model: CharacterGenerator = load_model(model,\n",
    "                                       \"macbeth(old)_LR0.0005_E4_BK256_V75_D256_B64_T8_H8_PN1024_DP0.2.pth\",\n",
    "                                       device=\"cpu\")\n",
    "\n",
    "block_size = 256\n",
    "dataset = CharacterDataset(get_text(\"macbeth(old)\"), block_size)\n",
    "\n",
    "seed_tokens = dataset.tokenised_text[:block_size].to(\"cpu\")\n",
    "input = \"\".join([dataset.decode[token.item()] for token in\n",
    " seed_tokens])\n",
    "print(f\"Input: \\n{input}\\nOutput:\")\n",
    "print(\"\".join([dataset.decode[token.item()] for token in\n",
    "       model.generate(seed_tokens, 500, block_size).squeeze(0)]))"
   ],
   "id": "c7f5ea2861defc9b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/v8/_7nzg4ln01d8js37_knftkp40000gp/T/ipykernel_61729/2326369167.py\", line 1, in <module>\n",
      "    from src.utils.io import load_model, get_text\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/src/utils/io.py\", line 6, in <module>\n",
      "    import torch\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/Eric/PycharmProjects/Transformer_no_hugging_face/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded macbeth(old)_LR0.0005_E4_BK256_V75_D256_B64_T8_H8_PN1024_DP0.2.pth from directory /Users/Eric/PycharmProjects/Transformer_no_hugging_face/models\n",
      "Input: \n",
      "﻿Title: Macbeth\n",
      "\n",
      "Author: William Shakespeare\n",
      "\n",
      "1606\n",
      "\n",
      "THE TRAGEDY OF MACBETH\n",
      "\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "\n",
      "\n",
      "Dramatis Personae\n",
      "\n",
      "  DUNCAN, King of Scotland\n",
      "  MACBETH, Thane of Glamis and Cawdor, a general in the King's\n",
      "army\n",
      "  LADY MACBETH, his wife\n",
      "  MACDUFF, Tha\n",
      "Output:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CharacterGenerator.generate() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 23\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([dataset\u001B[38;5;241m.\u001B[39mdecode[token\u001B[38;5;241m.\u001B[39mitem()] \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m\n\u001B[1;32m     20\u001B[0m  seed_tokens])\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mOutput:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([dataset\u001B[38;5;241m.\u001B[39mdecode[token\u001B[38;5;241m.\u001B[39mitem()] \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m        \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed_tokens\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblock_size\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)]))\n",
      "\u001B[0;31mTypeError\u001B[0m: CharacterGenerator.generate() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:53:47.885872Z",
     "start_time": "2025-03-23T15:53:35.477611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.engine.generate import generate\n",
    "from src.utils.io import load_model, get_text\n",
    "from src.utils.character_dataset import CharacterDataset\n",
    "from src.models.character_generator import CharacterGenerator\n",
    "\n",
    "model = CharacterGenerator(vocab_size=75,\n",
    "                           embedding_dim=256,\n",
    "                           num_transformers=8,\n",
    "                           num_heads=8,\n",
    "                           ffnn_hidden_neurons=1024)\n",
    "\n",
    "model: CharacterGenerator = load_model(model,\n",
    "                                       \"macbeth(old)_LR0.0005_E4_BK256_V75_D256_B64_T8_H8_PN1024_DP0.2.pth\",\n",
    "                                       device=\"cpu\")\n",
    "\n",
    "print(generate(get_text(\"macbeth(old)\"), model, 100, 256, \"cpu\", False))"
   ],
   "id": "2f64c78aa8f17a1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded macbeth(old)_LR0.0005_E4_BK256_V75_D256_B64_T8_H8_PN1024_DP0.2.pth from directory /Users/Eric/PycharmProjects/Transformer_no_hugging_face/models\n",
      "﻿Title: Macbeth\n",
      "\n",
      "Author: William Shakespeare\n",
      "\n",
      "1606\n",
      "\n",
      "THE TRAGEDY OF MACBETH\n",
      "\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "\n",
      "\n",
      "Dramatis Personae\n",
      "\n",
      "  DUNCAN, King of Scotland\n",
      "  MACBETH, Thane of Glamis and Cawdor, a general in the King's\n",
      "army\n",
      "  LADY MACBETH, his wife\n",
      "  MACDUFF, Thane of Fife, a nobleman of Scotland\n",
      "  LADY MACDUFF, his wife\n",
      "  MALCOLM, elder son of Duncan\n",
      "  DONALBA\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
